# SVM 之 从零推导

<!--more-->

{{< admonition warning >}}
KATEX 复杂公式渲染错误，问题还没有修复，后文内容待补充
{{< /admonition >}}

[支持向量机]^(Support Vector Machine) 是曾经火爆一时的分类模型，拥有华丽的数学理论包装。虽然在深度学习大行其道的今天，SVM 已渐显落寞，但是对每一个机器学习爱好者来说，了解一下它的前世今生也非常有必要。  

本文尝试用简单直白的语言描述 SVM 的推导过程，但鉴于个人水平有限，错误之处还请留言指出。

## SVM 基本型

在二维空间中给定一个二分类的数据集 $ D = (x_1,y_1),(x_2,y_2),...,(x_n,y_n), y_i \in -1,+1 $，我们在二维空间中找到一条直线能够将数据集中的两种样本分开，那么这个数据集就被称为线性可分。  

拓展到多维空间中，那就是在样本空间中找到一个超平面将两种样本区分开。这个超平面可以表示为： $$ \tag{1.1} \omega^T x + b = 0 $$  

<br />
，其中 ω 为平面的法向量，决定了超平面的方向，b 为位移项，决定了超平面与原点间的距离。  

由于超平面由法向量 ω 和位移项 b 即可确定，那么可以将超平面简单记为 (ω,b)。  

<br />
样本空间中任意一点到超平面 (ω,b) 的距离即为： $$ \tag{1.2} \gamma = \frac{\lvert \omega^T x + b \rvert}{\lVert \omega \rVert}$$  

<br />
我们假设超平面 (ω,b) 能够将给定的样本完美区分开，那么满足以下的不等式： 

{{< admonition warning >}}
KATEX渲染错误，待修复，后文待补充
{{< /admonition >}}

## 拉格朗日乘子法
## 对偶问题
## 核技巧

